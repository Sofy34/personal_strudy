# -*- coding: utf-8 -*-
"""playground.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/github/Sofy34/12.08/blob/master/playground.ipynb
"""

import os
import pandas as pd
import subprocess
import requests
from requests.adapters import HTTPAdapter
from requests.packages.urllib3.util.retry import Retry
import re
import glob
import defines
global sent_tex_db
global sent_tokens_db

localhost_yap = "http://localhost:8000/yap/heb/joint"
step_print = 100
db_step=300
# Commented out IPython magic to ensure Python compatibility.
def start_yap_api():
  cmd = "! ./yap api "
  process = subprocess.Popen(cmd,stdout=subprocess.PIPE,cwd="./external_src/yapproj/src/yap/",shell=True)
  return process

def try_yap():
  try_text = 'גנן גידל דגן בגן'
  localhost_yap = "http://localhost:8000/yap/heb/joint"
  data = '{{"text": "{}  "}}'.format(try_text).encode('utf-8')  # input string ends with two space characters
  headers = {'content-type': 'application/json'}
  response = requests.get(url=localhost_yap, data=data, headers=headers)
  json_response = response.json()
  return json_response

yap_tag_list = ['FROM','TO','FORM','LEMMA','CPOSTAG','POSTAG','FEATS','TOKEN']
# FROM: Index of the outgoing vertex of the edge
# TO: Index of the incoming vertex of the edge
# FORM: word form or punctuation mark
# LEMMA: Lemma of the word form; underscore if not available
# CPOSTAG: Coarse-grained part-of-speech tag; underscore if not available
# POSTAG: Fine-grained part-of-speech tag; underscore if not available; in YAP both POSTAG and CPOSTAG are always identical
# FEATS: List of morphological features separated by a vertical bar (|) from a pre-defined language-specific inventory; underscore if not available
# TOKEN: Source token index


def get_server_response(text,sent_idx):
  data = '{{"text": "{}  "}}'.format(text).encode('utf-8')  # input string ends with two space characters
  headers = {'content-type': 'application/json'}
  response = requests.get(url=localhost_yap, data=data, headers=headers)
  json_response = response.json()
  md_string = json_response.get('md_lattice','')
  if len(md_string) == 0:
    print("ERROR in get_server_response for {}\n{}".format(sent_idx,sent_text_db.iloc[sent_idx]))
  return md_string

def clean_server_response(text,sent_idx):
  clean_text= re.sub(r"(^./|.$/)","",text)
  clean_text = re.sub("\\t","\t",clean_text)
  clean_text = re.sub("\\n","\n",clean_text)
  return clean_text

def parse_server_response(text,sent_idx):
  rows = text.split("\n")
  for i,r in enumerate(rows):
    curr_word_idx = sent_tokens_db.shape[0]
    row_split = r.split('\t')
    for j,token in enumerate(row_split):
      if(len(token) == 0):
        continue
      sent_tokens_db.loc[curr_word_idx,yap_tag_list[j]] = token
      sent_tokens_db.loc[curr_word_idx,'sent_idx'] = sent_idx
      if(yap_tag_list[j] == 'FEATS' and '|' in token):
          feats_list = token.split("|")
          for n,fea in enumerate(feats_list):
            [name,value] = fea.split("=")
            sent_tokens_db.loc[curr_word_idx,"f_{}".format(name)] = value

def sent_to_tags(sent_idx):
  global sent_text_db
  text = sent_text_db.loc[sent_idx,'text']
  resp = get_server_response(text,sent_idx)
  if(sent_idx%step_print == 0):
    print("{} got response".format(sent_idx))
  if(len(resp)!=0):
    resp = clean_server_response(resp,sent_idx)
    if(sent_idx%step_print == 0):
      print("\t{} response cleaned".format(sent_idx))
    parse_server_response(resp,sent_idx)
    if(sent_idx%step_print == 0):
      print("\t{} response parsed".format(sent_idx))



def parse_all_sentenses(doc_list):
  global sent_text_db
  global sent_tokens_db
  doc_num = len(doc_list)
  for doc_idx,doc_path in enumerate(doc_list):
      print("Started doc {} of {}".format(doc_idx,doc_num))
      sent_text_db = pd.read_csv(doc_path,usecols=['text','doc_idx'])
      sent_tokens_db = pd.DataFrame()
      doc_idx_from_name = int(sent_text_db.loc[0,'doc_idx'])
      local_name = "{:02d}_sent_pos_db.csv".format(doc_idx_from_name)
      for sent_idx in sent_text_db.index:
        sent_to_tags(sent_idx)
      sent_tokens_db = sent_tokens_db.assign(doc_idx = sent_text_db['doc_idx'])
      sent_tokens_db.to_csv(os.path.join(os.getcwd(),defines.PATH_TO_DFS,local_name),index=False)
      del sent_tokens_db
      del sent_text_db
      # sent_tokens_db.to_csv(local_name,index=False)
      print('Saved db {}'.format(local_name))




